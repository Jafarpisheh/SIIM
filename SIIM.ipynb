{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Input, BatchNormalization, Activation, concatenate\n",
    "from tensorflow import feature_column\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import joblib\n",
    "\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "image_name          0\npatient_id          0\nsex                 0\nage                 0\nanatom              0\ndiagnosis           0\nbenign_malignant    0\ntarget              0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "df_train.rename(columns={'age_approx':'age', 'anatom_site_general_challenge':'anatom'}, inplace = True)\n",
    "df_train.dropna(axis=0, inplace = True)\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     image_name  patient_id     sex   age           anatom diagnosis  \\\n0  ISIC_2637011  IP_7279968    male  45.0        head/neck   unknown   \n1  ISIC_0015719  IP_3075186  female  45.0  upper extremity   unknown   \n2  ISIC_0052212  IP_2842074  female  50.0  lower extremity     nevus   \n3  ISIC_0068279  IP_6890425  female  45.0        head/neck   unknown   \n4  ISIC_0074268  IP_8723313  female  55.0  upper extremity   unknown   \n\n  benign_malignant  target  \n0           benign       0  \n1           benign       0  \n2           benign       0  \n3           benign       0  \n4           benign       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>anatom</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     image_name     sex   age           anatom  target\n0  ISIC_2637011    male  45.0        head/neck       0\n1  ISIC_0015719  female  45.0  upper extremity       0\n2  ISIC_0052212  female  50.0  lower extremity       0\n3  ISIC_0068279  female  45.0        head/neck       0\n4  ISIC_0074268  female  55.0  upper extremity       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>anatom</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "Tabular_data = df_train.drop(['benign_malignant', 'patient_id', 'diagnosis'], axis = 1)\n",
    "targets = df_train.target\n",
    "Tabular_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['data/jpeg/train/' + fname + '.jpg' for fname in Tabular_data.image_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabular_data = Tabular_data.drop(['image_name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 256\n",
    "def process_image(img_path):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  image = tf.io.read_file(img_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(image, tabular, target):\n",
    "    image = process_image(image)\n",
    "\n",
    "    return {'img_inp': image, 'tab_inp':  tabular}, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filenames\n",
    "#y = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "feature_input = {}\n",
    "\n",
    "\n",
    "age = feature_column.numeric_column('age')\n",
    "feature_columns.append(age)\n",
    "feature_input['age'] = tf.keras.Input(shape = (1,), name = 'age')\n",
    "\n",
    "age_buckets = feature_column.bucketized_column(age, boundaries=[30, 45, 85])\n",
    "feature_columns.append(age_buckets)\n",
    "#feature_input['age_buckets'] = tf.keras.Input(shape = (3,), name = 'age_buckets')\n",
    "\n",
    "sex = feature_column.categorical_column_with_vocabulary_list('sex', ['male', 'female'])\n",
    "sex = feature_column.indicator_column(sex)\n",
    "feature_columns.append(sex)\n",
    "feature_input['sex'] = tf.keras.Input(shape = (1,), name = 'sex', dtype = tf.string)\n",
    "\n",
    "anatom = feature_column.categorical_column_with_hash_bucket('anatom', hash_bucket_size=6)\n",
    "anatom = feature_column.indicator_column(anatom)\n",
    "feature_columns.append(anatom)\n",
    "feature_input['anatom'] = tf.keras.Input(shape = (1,), name = 'anatom', dtype=tf.string)\n",
    "\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "#feature_layer_outputs = feature_layer(feature_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'age': <tf.Tensor 'age_1:0' shape=(None, 1) dtype=float32>,\n 'sex': <tf.Tensor 'sex_1:0' shape=(None, 1) dtype=string>,\n 'anatom': <tf.Tensor 'anatom_1:0' shape=(None, 1) dtype=string>}"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "feature_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = [IMG_SIZE,IMG_SIZE, 3]\n",
    "HIDDEN_SIZE1 = 256\n",
    "HIDDEN_SIZE2 = 128\n",
    "HIDDEN_SIZE3 = 64\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_num_img = len(df_train)\n",
    "Num_mlg = np.count_nonzero(df_train.target)\n",
    "Num_bng = Total_num_img - Num_mlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weight_bng = 1/Num_bng * Total_num_img/2\n",
    "Weight_mlg = 1/Num_mlg * Total_num_img/2\n",
    "\n",
    "class_weights = {0: Weight_bng, 1: Weight_mlg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "  \"\"\"\n",
    "  Loads a saved model from a specified path.\n",
    "  \"\"\"\n",
    "  print(f\"Loading saved model from: {model_path}\")\n",
    "  model = tf.keras.models.load_model(model_path)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(retrain = False):\n",
    "    model = []\n",
    "    if retrain:\n",
    "        files = os.listdir('models')\n",
    "        paths = [os.path.join('models/', basename) for basename in files]\n",
    "        model_path = max(paths, key=os.path.getctime)\n",
    "        model = load_model(model_path)\n",
    "        #model.summary()\n",
    "    else:        \n",
    "        img_inp = Input(shape = INPUT_SIZE, name = 'img_inp')\n",
    "        #tab_inp = Input(shape = (), name = 'tab_inp', dtype = 'float32') \n",
    "\n",
    "        efnB3 = efn.EfficientNetB3(weights = 'imagenet', include_top = False)\n",
    "        x1 = efnB3(img_inp)\n",
    "        x1 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
    "\n",
    "        #x1 = Flatten()(x1)\n",
    "\n",
    "        x2 = feature_layer(feature_input)\n",
    "        x2 = Dense(50)(x2)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = Activation('relu')(x2)   \n",
    "\n",
    "        concat = concatenate([x1, x2])\n",
    "        #concat = x1\n",
    "        concat = Dense(256, activation = 'relu')(concat)\n",
    "        concat = BatchNormalization()(concat)\n",
    "        concat = Dropout(0.2)(concat)\n",
    "\n",
    "        \n",
    "        concat = Dense(128, activation = 'relu')(concat)\n",
    "        concat = BatchNormalization()(concat)\n",
    "        concat = Dropout(0.2)(concat)\n",
    "\n",
    "        \n",
    "        concat = Dense(64, activation = 'relu')(concat)\n",
    "        concat = BatchNormalization()(concat)\n",
    "        concat = Dropout(0.2)(concat)\n",
    "\n",
    "\n",
    "        outputs = Dense(OUTPUT_SIZE, activation= 'softmax')(concat)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = [img_inp, feature_input], outputs = outputs)\n",
    "        #model = tf.keras.models.Model(inputs = img_inp, outputs = outputs)\n",
    "\n",
    "        model.compile(\n",
    "                    optimizer = tf.keras.optimizers.SGD(lr = 1e-3),\n",
    "                    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics = [tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()])\n",
    "\n",
    "        #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = create_model(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensorboard_callback():\n",
    "  # Create a log directory for storing TensorBoard logs\n",
    "  logdir = os.path.join(\"logs\",\n",
    "                        # Make it so the logs get tracked whenever we run an experiment\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "  return tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = create_tensorboard_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "Rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=0, mode='auto', cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "272"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# How many rounds should we get the model to look through the data?\n",
    "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 45\n",
    "\n",
    "def get_data(X, Tabular_data):\n",
    "\n",
    "    x_train, x_val, tabular_train, tabular_val = train_test_split(X[:], Tabular_data[:], test_size = 0.2, random_state = 42)\n",
    "\n",
    "    y_train = pd.get_dummies(tabular_train.target)\n",
    "    tabular_train.drop('target', axis = 1, inplace = True)\n",
    "\n",
    "    y_val = pd.get_dummies(tabular_val.target)\n",
    "    tabular_val.drop('target', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_data = tf.data.Dataset.from_tensor_slices((tf.constant(x_train),dict(tabular_train),tf.constant(y_train)))\n",
    "    train_data = train_data.map(create_df).shuffle(buffer_size = len(x_train))\n",
    "    train_data = train_data.batch(BATCH_SIZE)\n",
    "    \n",
    "    \n",
    "    val_data = tf.data.Dataset.from_tensor_slices((tf.constant(x_val),dict(tabular_val),tf.constant(y_val)))\n",
    "    val_data = val_data.map(create_df).batch(BATCH_SIZE)\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_loop(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (str)\n",
    "  for clarity and reuse.\n",
    "  \"\"\"\n",
    "  \n",
    "  model_path = \"models/model\" + \"-\" + suffix + \".h5\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kfolds = KFold(folds, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nage (InputLayer)                [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nanatom (InputLayer)             [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nsex (InputLayer)                [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ndense_features_1 (DenseFeatures (None, 13)           0           age[0][0]                        \n                                                                 anatom[0][0]                     \n                                                                 sex[0][0]                        \n__________________________________________________________________________________________________\nimg_inp (InputLayer)            [(None, 256, 256, 3) 0                                            \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 50)           700         dense_features_1[0][0]           \n__________________________________________________________________________________________________\nefficientnet-b3 (Model)         multiple             10783528    img_inp[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 50)           200         dense_5[0][0]                    \n__________________________________________________________________________________________________\nglobal_average_pooling2d_1 (Glo (None, 1536)         0           efficientnet-b3[1][0]            \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 50)           0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1586)         0           global_average_pooling2d_1[0][0] \n                                                                 activation_1[0][0]               \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 256)          406272      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 256)          1024        dense_6[0][0]                    \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 256)          0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 128)          32896       dropout_3[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_6 (BatchNor (None, 128)          512         dense_7[0][0]                    \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 128)          0           batch_normalization_6[0][0]      \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 64)           8256        dropout_4[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_7 (BatchNor (None, 64)           256         dense_8[0][0]                    \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 64)           0           batch_normalization_7[0][0]      \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 2)            130         dropout_5[0][0]                  \n==================================================================================================\nTotal params: 11,233,774\nTrainable params: 11,145,482\nNon-trainable params: 88,292\n__________________________________________________________________________________________________\nEpoch 1/100\n11/11 [==============================] - 185s 17s/step - loss: 1.5756 - binary_accuracy: 0.4750 - auc_1: 0.4814 - val_loss: 1.3838 - val_binary_accuracy: 0.0333 - val_auc_1: 0.0176 - lr: 0.0010\nEpoch 2/100\n"
    }
   ],
   "source": [
    "targets_temp = Tabular_data.target\n",
    "models = []\n",
    "History = []\n",
    "# Set number of images to use for experimenting\n",
    "First_Image = 0\n",
    "Last_Image = 300\n",
    "\n",
    "for fold, (_, target_idx) in enumerate(kfolds.split(targets_temp)):\n",
    "    X_fold = [X[i] for i in list(target_idx)]\n",
    "    Tabular_fold = Tabular_data.iloc[target_idx]\n",
    "    [train_data, val_data] = get_data(X_fold, Tabular_fold)\n",
    "    if fold == 0:\n",
    "        model = create_model(False)\n",
    "    else:\n",
    "        model = create_model(True)\n",
    "\n",
    "    history = model.fit(train_data, epochs=NUM_EPOCHS, validation_data=val_data, validation_freq=1, callbacks=[EarlyStopping, Rate,tensorboard], class_weight = class_weights)\n",
    "    History.append(history)\n",
    "    sfx = \"EfficientNet3B_Img_Tab_fold{}\".format(fold)\n",
    "    save_model_loop(model, suffix=sfx)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history = model.fit(train_data, epochs=NUM_EPOCHS, validation_data=val_data, validation_freq=1, callbacks=[EarlyStopping, Rate,tensorboard], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'history'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-a5b949deba91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Validation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Training'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "plt.plot(History.history['val_loss'], color = 'red')\n",
    "plt.plot(History.history['loss'], color = 'blue')\n",
    "plt.legend(['Validation', 'Training'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (str)\n",
    "  for clarity and reuse.\n",
    "  \"\"\"\n",
    "  # Create model directory with current time\n",
    "  modeldir = os.path.join(\"models\",\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-7cbccafbb777>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"EfficientNet3B_Img_Tab\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "sfx = \"EfficientNet3B_Img_Tab\"\n",
    "save_model(model, suffix=sfx)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594966892380",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}