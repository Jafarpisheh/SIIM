{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n\n  diagnosis benign_malignant  target  \n0   unknown           benign       0  \n1   unknown           benign       0  \n2     nevus           benign       0  \n3   unknown           benign       0  \n4   unknown           benign       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>patient_id</th>\n      <th>sex</th>\n      <th>age_approx</th>\n      <th>anatom_site_general_challenge</th>\n      <th>diagnosis</th>\n      <th>benign_malignant</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_2637011</td>\n      <td>IP_7279968</td>\n      <td>male</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ISIC_0015719</td>\n      <td>IP_3075186</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0052212</td>\n      <td>IP_2842074</td>\n      <td>female</td>\n      <td>50.0</td>\n      <td>lower extremity</td>\n      <td>nevus</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ISIC_0068279</td>\n      <td>IP_6890425</td>\n      <td>female</td>\n      <td>45.0</td>\n      <td>head/neck</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ISIC_0074268</td>\n      <td>IP_8723313</td>\n      <td>female</td>\n      <td>55.0</td>\n      <td>upper extremity</td>\n      <td>unknown</td>\n      <td>benign</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets= df_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['data/jpeg/train/' + fname + '.jpg' for fname in df_train.image_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepration of Training and Validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets are in numeric format but our images are still just file paths.\n",
    "X = filenames\n",
    "y = pd.get_dummies(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset to train and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into tensors suitable for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 256\n",
    "def process_image(img_path):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  image = tf.io.read_file(img_path)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(image, target):\n",
    "  \"\"\"\n",
    "  Creates the dataset tensors.\n",
    "  \"\"\"\n",
    "    image = process_image(image)\n",
    "    return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images to be loded in each loop\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create training and validation data batches\n",
    "train_data = tf.data.Dataset.from_tensor_slices((tf.constant(x_train), tf.constant(y_train)))\n",
    "train_data = train_data.map(create_df).batch(BATCH_SIZE).shuffle(buffer_size=len(x_train))\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((tf.constant(x_val), tf.constant(y_val)))\n",
    "val_data = val_data.map(create_df).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the weights for the unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is heavily unbalanced. Therefore it is essential to calculate the weight of each class\n",
    "\n",
    "Total_num_img = len(df_train)\n",
    "Num_mlg = np.count_nonzero(df_train.target)\n",
    "Num_bng = Total_num_img - Num_mlg\n",
    "\n",
    "Weight_bng = 1/Num_bng * Total_num_img/2\n",
    "Weight_mlg = 1/Num_mlg * Total_num_img/2\n",
    "\n",
    "class_weights = {0: Weight_bng, 1: Weight_mlg}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase a pre-trained model is required to be loaded\n",
    "def load_model(model_path):\n",
    "  \"\"\"\n",
    "  Loads a saved model from a specified path.\n",
    "  \"\"\"\n",
    "  print(f\"Loading saved model from: {model_path}\")\n",
    "  model = tf.keras.models.load_model(model_path)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the input, hidden layer and output of the neural network\n",
    "INPUT_SIZE = [None, IMG_SIZE,IMG_SIZE, 3]\n",
    "HIDDEN_SIZE = 128\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(retrain = False):\n",
    "    model = []\n",
    "    if retrain:\n",
    "        files = os.listdir('models')\n",
    "        paths = [os.path.join('models/', basename) for basename in files]\n",
    "        model_path = max(paths, key=os.path.getctime)\n",
    "        model = load_model(model_path)\n",
    "        model.summary()\n",
    "    else:\n",
    "        model = Sequential([\n",
    "                    Conv2D(64, kernel_size = 5, padding = 'VALID', activation = 'relu'),\n",
    "                    MaxPooling2D(pool_size = 5),\n",
    "\n",
    "                    Conv2D(128, kernel_size = 5, padding = 'VALID', activation = 'relu'),\n",
    "                    MaxPooling2D(pool_size = 5),\n",
    "                    \n",
    "                    Conv2D(256, kernel_size = 5, padding = 'VALID', activation = 'relu'),\n",
    "                    MaxPooling2D(pool_size = 5),\n",
    "                    \n",
    "                    Flatten(),\n",
    "                    Dense(HIDDEN_SIZE,activation='relu'),\n",
    "                    Dense(OUTPUT_SIZE, activation='softmax')])\n",
    "\n",
    "        model.build(INPUT_SIZE)\n",
    "\n",
    "        model.compile(\n",
    "                    optimizer = tf.keras.optimizers.SGD(lr = 1e-2),\n",
    "                    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                    metrics = ['val_AUC'])\n",
    "\n",
    "        model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = create_model(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating callbacks\n",
    "EarlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 4)\n",
    "Rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto', cooldown=0, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rounds should we get the model to look through the data?\n",
    "NUM_EPOCHS = 100 \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_data, epochs=NUM_EPOCHS, validation_data=val_data, validation_freq=1, callbacks=[EarlyStopping, Rate], class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'], color = 'red')\n",
    "plt.plot(history.history['loss'], color = 'blue')\n",
    "plt.legend(['Validation', 'Training'])\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (str)\n",
    "  for clarity and reuse.\n",
    "  \"\"\"\n",
    "  # Create model directory with current time\n",
    "  modeldir = os.path.join(\"models\",\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sfx = \"Images_CNN\"\n",
    "save_model(model, suffix=sfx)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595517739446",
   "display_name": "Python 3.7.6 64-bit ('User': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}